{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), '../data/3_targets_1')\n",
    "PROCESSED_DATA_PATH = os.path.join(os.getcwd(), '../processed/3_targets')\n",
    "#Delete folder if it exists\n",
    "if os.path.exists(PROCESSED_DATA_PATH):\n",
    "    os.system('rm -rf ' + PROCESSED_DATA_PATH)\n",
    "#Create folder\n",
    "if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "    os.makedirs(PROCESSED_DATA_PATH)\n",
    "if not os.path.exists(os.path.join(PROCESSED_DATA_PATH,'images')):\n",
    "    os.makedirs(os.path.join(PROCESSED_DATA_PATH,'images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gazebo Param: \n",
    "#Definition: https://github.com/ros-simulation/gazebo_ros_pkgs/blob/398cde933cba5d72921055d57d4faa47c4445654/gazebo_plugins/src/gazebo_ros_camera_utils.cpp#L524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camera parameters\n",
    "#Definitions: https://docs.nerf.studio/quickstart/data_conventions.html\n",
    "\n",
    "fl_x = 762.72 # focal length in x\n",
    "fl_y = 762.72# focal length in y\n",
    "w = 1280 # image width\n",
    "h = 720 # image height\n",
    "cx = w//2 # optical center in x\n",
    "cy = h//2 # optical center in y\n",
    "camera_model = \"OPENCV\" # camera model\n",
    "k1 = 0 # radial distortion coefficient k1\n",
    "k2 = 0 # radial distortion coefficient k2\n",
    "k3 = 0 # radial distortion coefficient k3\n",
    "p1 = 0 # tangential distortion coefficient p1\n",
    "p2 = 0 # tangential distortion coefficient p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_tf_to_matrix(tf):\n",
    "    #Tf given as robot relative to camera as origin\n",
    "    #We want to invert this and set the robot as the origin\n",
    "    matrix = np.zeros((4,4))\n",
    "    matrix[0][3] = -tf[0]\n",
    "    matrix[1][3] = -tf[1]\n",
    "    matrix[2][3] = -tf[2]\n",
    "    matrix[3][3] = 1\n",
    "\n",
    "    r = Rotation.from_rotvec(tf[3:])\n",
    "    matrix[:3,:3] = r.as_dcm().T # Transpose the 3x3 rotation matrix\n",
    "\n",
    "    print(r.as_dcm())\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'scipy.spatial.transform._rotation.Rotation' object has no attribute 'as_dcm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(data_tf, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimages/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(data_cnt)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m transform_matrix \u001b[39m=\u001b[39m from_tf_to_matrix(tf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#Append to frames\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m frames\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfile_path\u001b[39m\u001b[39m\"\u001b[39m: file_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtransform_matrix\u001b[39m\u001b[39m\"\u001b[39m: transform_matrix\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m })\n",
      "\u001b[1;32m/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m matrix[\u001b[39m3\u001b[39m][\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m r \u001b[39m=\u001b[39m Rotation\u001b[39m.\u001b[39mfrom_rotvec(tf[\u001b[39m3\u001b[39m:])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m matrix[:\u001b[39m3\u001b[39m,:\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mas_dcm()\u001b[39m.\u001b[39mT \u001b[39m# Transpose the 3x3 rotation matrix\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(r\u001b[39m.\u001b[39mas_dcm())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boomalope/nerf_estimator/src/nerf_estimator/nerf_vision/scripts/data_processing.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m matrix\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'scipy.spatial.transform._rotation.Rotation' object has no attribute 'as_dcm'"
     ]
    }
   ],
   "source": [
    "data_cnt = 0\n",
    "frames = []\n",
    "while True:\n",
    "    #Get data paths\n",
    "    data_img = os.path.join(DATA_PATH, '{}.png'.format(data_cnt))\n",
    "    data_tf= os.path.join(DATA_PATH, '{}.txt'.format(data_cnt))\n",
    "\n",
    "    if not os.path.exists(data_img):\n",
    "        break\n",
    "    \n",
    "    #Get tf as np array\n",
    "    tf = np.loadtxt(data_tf, delimiter=',')\n",
    "\n",
    "\n",
    "    file_path = \"images/{}.png\".format(data_cnt)\n",
    "    transform_matrix = from_tf_to_matrix(tf)\n",
    "\n",
    "    #Append to frames\n",
    "    frames.append({\n",
    "        \"file_path\": file_path,\n",
    "        \"transform_matrix\": transform_matrix.tolist(),\n",
    "    })\n",
    "\n",
    "    #Save image in processed folder\n",
    "    img = cv2.imread(data_img)\n",
    "    cv2.imwrite(os.path.join(PROCESSED_DATA_PATH, file_path), img)\n",
    "    \n",
    "    data_cnt += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dictionary = {}\n",
    "transform_dictionary[\"fl_x\"] = fl_x\n",
    "transform_dictionary[\"fl_y\"] = fl_y\n",
    "transform_dictionary[\"cx\"] = cx\n",
    "transform_dictionary[\"cy\"] = cy\n",
    "transform_dictionary[\"k1\"] = k1\n",
    "transform_dictionary[\"k2\"] = k2\n",
    "transform_dictionary[\"k3\"] = k3\n",
    "transform_dictionary[\"p1\"] = p1\n",
    "transform_dictionary[\"p2\"] = p2\n",
    "transform_dictionary[\"camera_model\"] = camera_model\n",
    "transform_dictionary[\"frames\"] = frames\n",
    "\n",
    "#Save as json \n",
    "with open(os.path.join(PROCESSED_DATA_PATH, \"transforms.json\"), 'w') as outfile:\n",
    "    json.dump(transform_dictionary, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
